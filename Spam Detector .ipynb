{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Naive Bayes Algorithm, Support Vector Machine Algrothim, and Random Forest Algrothim:\n",
    "### Building a Spam Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### What is Naive Bayes Algorithm ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Naive Bayes are probabilistic models that apply \"Bayes Theorem\" to make classification on a set of data assuming that there is strong independence between features. This independency means that the existence of a certain feature is unrelated to the existence of other features. For example, grape has a purple color, round shape and sweet taste. Naive Bayes would consider each feature of the grape to contribute indepently to the probability of classfying the fruit to grape regardless of the correlations between these three features. Due to the ease of implementation, Naive Bayes provides very good performing models in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### How Naive Bayes Works ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# importing needed libraries to display the Naive Bayes rule\n",
    "import requests \n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "%matplotlib inline\n",
    "response = requests.get(\"https://miro.medium.com/max/998/1*Lt8E08oxEnnRegLbNBzNAg.png\")\n",
    "image = Image.open(BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=998x221 at 0x7F694405A0F0>"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#displaying the Naive Bayes rule\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To find the posterior probability of a certain event \"A\", it uses the probabilities of prior events. Refer to the above formela for the mathmatical representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### What are the advantages and disadvantages of Naive Bayes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Advantages:\n",
    "\n",
    "1. When assumption of independent predictors holds true, a Naive Bayes classifier performs better as compared to other models.\n",
    "\n",
    "2. Naive Bayes requires a small amount of training data to estimate the test data. So, the training period is less.\n",
    "\n",
    "3. Naive Bayes is also easy to implement.\n",
    "\n",
    "4. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This helps with problems derived from the curse of dimensionality and improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Disadvantages:\n",
    "\n",
    "1. Main imitation of Naive Bayes is the assumption of independent predictors. Naive Bayes implicitly assumes that all the attributes are mutually independent. In real life, it is almost impossible that we get a set of predictors which are completely independent.\n",
    "\n",
    "2. If categorical variable has a category in test data set, which was not observed in training data set, then model will assign a 0 (zero) probability and will be unable to make a prediction. This is often known as Zero Frequency. To solve this, we can use the smoothing technique. One of the simplest smoothing techniques is called Laplace estimation.\n",
    "\n",
    "3. Although they are pretty good classifiers, naive bayes are know to be poor estimators. So the probability that outputs from it shouldn’t be taken very seriously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### What is Support Vector Machine Algorithm (SVM) ?\n",
    "\n",
    "It's an algrothim that is used in supervised learning , meaning training data is labled, to find the optimal seprating line between different classes of data. The objective of SVM is to find the plane with the maximum margin or distance between data points of different classes to provide more space for future data points to be classfied correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### What are the advantages and disadvantages of SVM ?\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. When there is a clear margin of separation between different classes, SVM works relatively well.\n",
    "2. In high dimensional spaces, SVM works more effectively.\n",
    "3. When the number of dimensions is greater than the number of samples, SVM is more effective.\n",
    "4. SVM is memory efficient algorithim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Disadvantages:\n",
    "\n",
    "1. For large number of data points, SVM is not suitable.\n",
    "2. When the data set has more noise ( ex: target classes are overlapping), SVM will not perform very well.\n",
    "3. When the number of features for each data point exceeds the number of training data points, the SVM will not perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Introduction : What is Random Forest Algorithm ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The Random Forest Model is based on the idea of Decision Trees; it combines a group of decision trees that each is trained using different set of features to split the data set. At the final step, the final predictions are then decided by taking the average predictions of all decision trees. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### What are the advantages and disadvantages of Random Forest ?\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. Using bagging algorithm and ensembling learning teqchnique, Random Forest produces as many trees from the data set and then combines the final output based on all these trees. Thus, it reduces the problems of overfitting and variance in a way that improves the accuracy of its results.\n",
    "2. Classification and regression problems can be solved using Random Forest Algorthim. \n",
    "3. Categorical and continuous variables works well with Random Forest.\n",
    "4. Using Random Forest, missing values can be handled automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Disadvantages:\n",
    "\n",
    "1. Random Forest can be a complex algorthim as it creates many trees,compared to Decision Tree, and combines their outputs in its final result. Using Sklearn Library, it creates 100 trees by defult. \n",
    "2. Random Forest can consume a long time in training data, when it's compared to Decision Trees, because it generates many trees and makes the final decision based on average of all the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Spam Detector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Spam detection is one of the vital features that is implied in any email service provider. In this project, I will use the Naive Bayes and Support Vector Machine to train provided data to classfiy emails with or without spam and compare their performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The project steps will be as the following : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Exploring the dataset.\n",
    "2. Introduction to Bag of Words (BoW) and Sci-kit implementation.\n",
    "3. Splitting Dataset in training and testing set.\n",
    "4. Applying BoW to process the dataset.\n",
    "5. Naive Bayes Implementation with sci-kit learn.\n",
    "6. SVM Implementation with sci-kit learn.\n",
    "7. Random Forest Implementation with sci-kit learn.\n",
    "8. Models evaluation.\n",
    "9. Conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Exploring the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The data set that will be used for this project is imported from Kaggle Website(online platform for data scientists and machine learners).\n",
    "\n",
    "The data set link : https://www.kaggle.com/balakishan77/spam-or-ham-email-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# pandas library is imported (pandas package is used for exploring and cleaning data sets)\n",
    "import pandas as pd\n",
    "# openning the data set file\n",
    "df = pd.read_csv(\"spamham.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the first five rows \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As show in the previous table, the column 'text' is for the emails text, and the 'spam' column has values of 1 and 0 to classify emails. 1 for spam emails and 0 for non spam emails.\n",
    "\n",
    "It can be also noticed that the word 'Subject:' is repeated in each email text. They need to be removed to avoid altering the analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# using the lampda function to loop in all emails and remove 'Subject:'\n",
    "df['text'] = df['text'].apply(lambda x:x.replace('Subject:',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naturally irresistible your corporate identit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the stock trading gunslinger  fanny is merril...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unbelievable new homes made easy  im wanting ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 color printing special  request additional ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do not have money , get software cds from her...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0   naturally irresistible your corporate identit...     1\n",
       "1   the stock trading gunslinger  fanny is merril...     1\n",
       "2   unbelievable new homes made easy  im wanting ...     1\n",
       "3   4 color printing special  request additional ...     1\n",
       "4   do not have money , get software cds from her...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the data set to make sure the email fix worked well \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Introduction to Bag of Words (BoW) and Sci-kit implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The project data set has 5739 rows. The model used will only accept numerical data as input,so I should process the emails text. Thus, the Bag of Word is an essential algrothim in this project. This algrothim takes the text and count the frequency of the words in the given text. BoW treats each word indepently and ignores the order of the word. I can convert the emails text into a matrix, with each email as a row and each word(token) is a column, and the corresponding (row,column) values beign the frequency of occurrence of each word or token in that emails data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To apply the BoW conpcet, I will use the sklearns CountVectorizer method that does the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. It tokenizes the string(separates the string into individual words) and gives an integer ID to each token.\n",
    "2. It counts the occurrence of each of those tokens.\n",
    "3. It automatically converts all tokenized words to their lower case form so that it does not treat words like ‘He’ and ‘he’ differently.\n",
    "4. It also ignores all punctuation so that words followed by a punctuation mark (for example: ‘hello!’) are not treated differently than the same words not prefixed or suffixed by a punctuation mark (for example: ‘hello’).\n",
    "5. The third parameter to take note of is the stop_words parameter. Stop words refer to the most commonly used words in a language. They include words like 'am', 'an', 'and', 'the' etc. By setting this parameter value to english, CountVectorizer will automatically ignore all words(from input text) that are found in the built in list of english stop words in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Splitting Dataset in Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I want to split data so it has the following structure:\n",
    "1. X_train is my training data for the 'text' column.\n",
    "2. y_train is my training data for the 'label' column.\n",
    "3. X_test is my testing data for the 'text' column.\n",
    "4. y_test is my testing data for the 'label' column.\n",
    "\n",
    "Note: I will print out the number of rows I have in each training and testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total data set 5728\n",
      "Number of rows in the training set 4296\n",
      "Number of rows in the testing set 1432\n"
     ]
    }
   ],
   "source": [
    "# splitting my data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(df['text'],df['spam'], random_state = 42)\n",
    "\n",
    "print('Number of rows in the total data set {}'.format(df.shape[0]))\n",
    "\n",
    "print('Number of rows in the training set {}'.format(x_train.shape[0]))\n",
    "\n",
    "print('Number of rows in the testing set {}'.format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Applying BoW to Process the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After splitting the data set into training and testing sets, I will use the CountVectorizer() to \n",
    "build a matrix dispalying all frecuencies for emails words by following these steps:\n",
    "\n",
    "1. I will fit (x_train), the training data, into the CountVectorizer() and return the resulted matrix.\n",
    "\n",
    "2. I will transfom the (x_test), the testing data, to return the matrix.\n",
    "\n",
    "Note : X_train is the training data for the \"Text\" column in the dataset, and I will use it to train my model.\n",
    "X_test is the testing data for also the same column \"Text\", and I will use it (after beign transformed into a matrix) to make predictions on. Later, I will compare the results of these predictions with Y_test , which corresponds to the \"Spam\" classifcation column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# preparing the CountVectoizer\n",
    "count_vector = CountVectorizer()\n",
    "\n",
    "# fitting and transforming the x_train into the matrix model\n",
    "training_data = count_vector.fit_transform(x_train)\n",
    "\n",
    "# transforming the testing_data to a matrix \n",
    "testing_data = count_vector.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Naive Bayes Implementation with Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I will be use the multinomial Naive Bayes implementation. This classifier is used for classificying data with discrete features (such as in my project case, word counts for text classification). This model takes the count of words as input. While the normal,Gaussian,distribuation is used in the case of continuous data as it assumes that the input data has a noraml, Gaussian, distribuation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# preparing MultinomiaNB model \n",
    "n_bayes = MultinomialNB()\n",
    "# fitting the previous trained data with y_train into the model\n",
    "n_bayes.fit(training_data,y_train)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# making predictions using the previous prepared testing_data\n",
    "predictions_nbayes = n_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Support Vector Machine Implementation with Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# preparing SVM model\n",
    "svm_model = SVC()\n",
    "# fitting the previous trained data with y_train into the model\n",
    "svm_model.fit(training_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# making predictions using the previous prepared testing_data\n",
    "predictions_svm = svm_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Random Forest Implementation with Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# preparing the random forest model\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "# fitting the random forest model\n",
    "random_forest.fit(training_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# making predictions using the previous prepared testing_data\n",
    "predictions_rf = random_forest.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Models evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After fitting my model and making predictions, I need know how are my two models are preforming. \n",
    "Therefore, I will make some tests in my trained model to find the accuracys score, precision and sensitivity:\n",
    "\n",
    "1. Accuracy Score: it measures how often the clasifier model is making correct predictions on the data set. It's calculated as the number of correct predictions divided by the total number of predictions (it's the number of the test data points).\n",
    "\n",
    "2. Precision : it calculates the proprtion of emails that were classified as spam by us, actually were spam. \n",
    "\n",
    "Precision = True Positives (words classfied as spam , and which are actually spam) / ( True Positives  + False Positives ) (all words classified as spam, whether they were classfied correctly or uncorrectly). \n",
    "\n",
    "3. Sensitivity (Recall) : it finds the proportion of emails that are actually were spam classified by us as spam. \n",
    "\n",
    "Sensitivity = True Positives (words classfied as spam , and which are actually spam) / (True Positives + False Negatives)(all words that are actually spam). \n",
    "\n",
    "4. F1 : is a measure that used to find the best balance between precision and sensitivity scores and in the case of high number of large negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Evaluation of Naive Bayes Algorithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.9874301675977654\n",
      "Precision score is: 0.9782016348773842\n",
      "Sensitivity score is: 0.9728997289972899\n",
      "F1 Score is: 0.9755434782608696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy score is:\",format(accuracy_score(y_test,predictions_nbayes)))\n",
    "\n",
    "print(\"Precision score is:\",format(precision_score(y_test,predictions_nbayes)))\n",
    "\n",
    "print(\"Sensitivity score is:\",format(recall_score(y_test,predictions_nbayes)))\n",
    "\n",
    "print(\"F1 Score is:\",format(f1_score(y_test,predictions_nbayes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Naive Bayes algorithim is performing very well on all the four evaluations matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Evaluation of Support Vector Machine Alogrithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.9392458100558659\n",
      "Precision score is: 0.9862068965517241\n",
      "Sensitivity score is: 0.7750677506775068\n",
      "F1 Score is: 0.8679817905918058\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is:\",format(accuracy_score(y_test,predictions_svm)))\n",
    "\n",
    "print(\"Precision score is:\",format(precision_score(y_test,predictions_svm)))\n",
    "\n",
    "print(\"Sensitivity score is:\",format(recall_score(y_test,predictions_svm)))\n",
    "\n",
    "print(\"F1 Score is:\",format(f1_score(y_test,predictions_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "SVM algorithim is performing somehow good, but not out performing like Naive Bayes. I will use GridSearchCV library to find the optiomal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing GridSearchCv library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# paramters to find its values that would make SVM perform better\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "# bulding SVC model\n",
    "svr = SVC()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "# fitting data\n",
    "clf.fit(training_data, y_train)\n",
    "# displaying the best parameters values \n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# re-bulding SVM model using the found paramters\n",
    "svm_model = SVC(C = 10, kernel = \"linear\")\n",
    "# fitting the previous trained data with y_train into the model\n",
    "svm_model.fit(training_data, y_train)\n",
    "# making predictions\n",
    "predictions_svm = svm_model.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.9853351955307262\n",
      "Precision score is: 0.9860335195530726\n",
      "Sensitivity score is: 0.9566395663956639\n",
      "F1 Score is: 0.9711141678129297\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is:\",format(accuracy_score(y_test,predictions_svm)))\n",
    "\n",
    "print(\"Precision score is:\",format(precision_score(y_test,predictions_svm)))\n",
    "\n",
    "print(\"Sensitivity score is:\",format(recall_score(y_test,predictions_svm)))\n",
    "\n",
    "print(\"F1 Score is:\",format(f1_score(y_test,predictions_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Conclusion \n",
    "\n",
    "After finding the best paramters for SVM, the model performance has imporved and become nearly the same as Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Evaluation of Random Forest Alogrithim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is: 0.9581005586592178\n",
      "Precision score is: 1.0\n",
      "Sensitivity score is: 0.8373983739837398\n",
      "F1 Score is: 0.911504424778761\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is:\",format(accuracy_score(y_test,predictions_rf)))\n",
    "\n",
    "print(\"Precision score is:\",format(precision_score(y_test,predictions_rf)))\n",
    "\n",
    "print(\"Sensitivity score is:\",format(recall_score(y_test,predictions_rf)))\n",
    "\n",
    "print(\"F1 Score is:\",format(f1_score(y_test,predictions_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Conclusion \n",
    "\n",
    "The Random Forest is performing well;however is not as good as the previous two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Final Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After applying the three previous models and evaluating them, I can say that Naive Bayes is the best performing then come SVM and finally Random Forest in detecting emails with spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Refrecnes \n",
    "\n",
    "https://towardsdatascience.com/naive-bayes-intuition-and-implementation-ac328f9c9718\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifiers\n",
    "\n",
    "http://theprofessionalspoint.blogspot.com/2019/03/advantages-and-disadvantages-of-naive.html\n",
    "\n",
    "https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9\n",
    "\n",
    "https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72\n",
    "\n",
    "https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47\n",
    "\n",
    "https://medium.com/@dhiraj8899/top-4-advantages-and-disadvantages-of-support-vector-machine-or-svm-a3c06a2b107\n",
    "\n",
    "https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76\n",
    "\n",
    "http://theprofessionalspoint.blogspot.com/2019/02/advantages-and-disadvantages-of-random.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}